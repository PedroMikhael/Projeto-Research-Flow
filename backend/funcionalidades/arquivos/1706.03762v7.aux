\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{brazil}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Model Architecture}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Encoder and Decoder Stacks}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Attention}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Scaled Dot-Product Attention}{3}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Multi-Head Attention}{4}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Applications of Attention in our Model}{4}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Position-wise Feed-Forward Networks}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Embeddings and Softmax}{4}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Positional Encoding}{5}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Why Self-Attention}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Training}{6}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Training Data and Batching}{6}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Hardware and Schedule}{6}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Optimizer}{6}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Regularization}{6}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{7}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Machine Translation}{7}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Model Variations}{7}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}English Constituency Parsing}{9}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{9}{section.7}\protected@file@percent }
\bibcite{Ba2016LayerN}{1}
\bibcite{Bahdanau2014NeuralMT}{2}
\bibcite{Britz2017MassiveEON}{3}
\bibcite{Cheng2016LongSL}{4}
\bibcite{Cho2014LearningPR}{5}
\bibcite{Chollet2016XceptionDL}{6}
\bibcite{Chung2014EmpiricalEO}{7}
\bibcite{Dyer2016RecurrentNN}{8}
\bibcite{Gehring2017ConvolutionalST}{9}
\bibcite{Graves2013GeneratingSW}{10}
\bibcite{He2016DeepRL}{11}
\bibcite{Hochreiter2001GradientFI}{12}
\bibcite{Hochreiter1997LongST}{13}
\bibcite{Huang2009Self-trainingPG}{14}
\bibcite{Jozefowicz2016ExploringTL}{15}
\bibcite{Kaiser2016CanAM}{16}
\bibcite{Kaiser2016NeuralGL}{17}
\bibcite{Kalchbrenner2017NeuralMT}{18}
\bibcite{Kim2017StructuredAN}{19}
\bibcite{Kingma2015AdamAM}{20}
\bibcite{Kuchaiev2017FactorizationTF}{21}
\bibcite{Lin2017AAS}{22}
\bibcite{Luong2015Multi-taskST}{23}
\bibcite{Luong2015EffectiveAT}{24}
\bibcite{Marcus1993BuildingAL}{25}
\bibcite{McClosky2006EffectiveSF}{26}
\bibcite{Parikh2016ADAM}{27}
\bibcite{Paulus2017ADR}{28}
\bibcite{Petrov2006LearningAC}{29}
\bibcite{Press2016UsingTE}{30}
\bibcite{Sennrich2015NeuralMT}{31}
\bibcite{Shazeer2017OutrageouslyLN}{32}
\bibcite{Srivastava2014DropoutAS}{33}
\bibcite{Sukhbaatar2015End-to-endMN}{34}
\bibcite{Sutskever2014SequenceTS}{35}
\bibcite{Szegedy2015RethinkingTI}{36}
\bibcite{Vinyals2015GrammarAA}{37}
\bibcite{Wu2016GooglesNM}{38}
\bibcite{Zhou2016DeepRM}{39}
\bibcite{Zhu2013FastAA}{40}
\newlabel{LastPage}{{7}{12}{Attention Visualizations}{page.12}{}}
\gdef\lastpage@lastpage{12}
\gdef\lastpage@lastpageHy{12}
\gdef \@abspage@last{12}
